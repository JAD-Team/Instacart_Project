{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Joining Tables with AWS Glue Studio\n","\n","#### 1. Getting started\n","\n","The dataset we'll be using is from S3, at:\n","\n","    s3://imba-andy/features/\n","\n","It contains data in parquet format.\n","\n","Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["import sys\n","from awsglue.transforms import *\n","from awsglue.utils import getResolvedOptions\n","from pyspark.context import SparkContext\n","from awsglue.context import GlueContext\n","from awsglue.job import Job"]},{"cell_type":"markdown","metadata":{},"source":["#### 2. Joining\n","\n","We will write a script that:\n","\n","1. Set up a single `GlueContext`.\n","2. Creating dataframes from existing athena catelog\n","3. Combines up_feature_db, prd_feature_db, user_feature_db and user_feature_2_db into a single \n","data set. This is often referred to as de-normalization.\n","4. Write the output as a single csv file to S3, at `s3://imba-andy/features-output/`"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# create glue context first\n","glueContext = GlueContext(SparkContext.getOrCreate())\n","    \n","    \n","# creating dataframes from existing athena catelog\n","up_features = glueContext.create_dynamic_frame_from_options(connection_type = \"parquet\", connection_options = {\"paths\": [\"s3://imba-andy/features/up-feature-db/\"]})\n","prd_features = glueContext.create_dynamic_frame_from_options(connection_type = \"parquet\", connection_options = {\"paths\": [\"s3://imba-andy/features/prd-feature-db/\"]})\n","user_features_1 = glueContext.create_dynamic_frame_from_options(connection_type = \"parquet\", connection_options = {\"paths\": [\"s3://imba-andy/features/user-feature-db/\"]})\n","user_features_2 = glueContext.create_dynamic_frame_from_options(connection_type = \"parquet\", connection_options = {\"paths\": [\"s3://imba-andy/features/user-feature-2-db/\"]})"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# join user features together\n","users = Join.apply(user_features_1.rename_field('user_id','user_id1'), user_features_2, 'user_id1', 'user_id').drop_fields(['user_id1'])\n","    \n","# join everything together\n","df = Join.apply(Join.apply(up_features, \n","                      users.rename_field('user_id','user_id1'), \n","                      'user_id','user_id1').drop_fields(['user_id1']),\n","          prd_features.rename_field('product_id','product_id1'), \n","          'product_id','product_id1').drop_fields(['product_id1'])"]},{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# convert glue dynamic dataframe to spark dataframe\n","df_spark = df.toDF()\n","df_spark.repartition(1).write.mode('overwrite').format('csv').save(\"s3://imba-andy/features-output\", header = 'true')"]}],"metadata":{"kernelspec":{"display_name":"Glue PySpark","language":"python","name":"glue_pyspark"},"language_info":{"codemirror_mode":{"name":"python","version":3},"file_extension":".py","mimetype":"text/x-python","name":"Python_Glue_Session","pygments_lexer":"python3"}},"nbformat":4,"nbformat_minor":4}
